# ConvaiText-Image
# ğŸ”® Unreal Bot Context Visualizer

Projeto criado em **Unreal Engine 5.3** totalmente em **Blueprints**, que conecta um sistema de diÃ¡logo com lÃ³gica de contexto e visualizaÃ§Ã£o multimÃ­dia em um ambiente 3D interativo.

---

## ğŸ¯ Objetivo

Detectar falas de um bot, analisar seu conteÃºdo e exibir dinamicamente **imagens, vÃ­deos ou modelos 3D** com base em:

- **Contexto geral da fala**
- **Palavras-chave especÃ­ficas** (inclusive compostas)

---

## ğŸ› ï¸ Tecnologias e Plugins

- **Unreal Engine 5.3**
- **Blueprint Only** (sem cÃ³digo C++)
- Plugins utilizados:
  - [**Convai Plugin**](https://www.convai.com/) â€“ sistema de diÃ¡logo com bots inteligentes
  - [**HttpBlueprint**](https://www.unrealengine.com/marketplace/en-US/product/http-request-blueprints) â€“ requisiÃ§Ãµes HTTP assÃ­ncronas para APIs externas

---

## ğŸŒ IntegraÃ§Ãµes com API

O projeto faz uso das seguintes APIs externas:

### ğŸ¤– Convai API
- Utilizada para controlar a lÃ³gica de conversaÃ§Ã£o com o bot
- Evento de fala (`OnBotSpoke`) dispara o processamento de contexto ou palavra-chave

### ğŸ“Š Hugging Face Inference API
- **Modelo:** `facebook/bart-large-mnli`
- Endpoint: `https://api-inference.huggingface.co/models/facebook/bart-large-mnli`
- Utilizado para **classificaÃ§Ã£o de intenÃ§Ã£o/contexto** com base em `candidate_labels` extraÃ­dos da Data Table
- A resposta define qual tipo de conteÃºdo deve ser exibido no mundo

---

## ğŸ“š Estrutura do Projeto

### ğŸ¤ `BotSpeechAnalyzer` (Actor)

- Recebe eventos de fala do bot (via Convai)
- Envia o texto para a API Hugging Face para anÃ¡lise de contexto
- Trata a resposta e decide o tipo de asset a exibir com base em Data Tables

### ğŸ§  DataTables

#### `DT_ContextAssets`

- Mapeia contextos como `"cidade"`, `"floresta"` etc.
- Define o tipo de asset (imagem, vÃ­deo, modelo 3D)

#### `DT_KeywordAssets`

- Mapeia palavras-chave como `"fÃ­sica quÃ¢ntica"`, `"robÃ³tica"` etc.
- Associadas diretamente a um asset (sem depender de contexto geral)

---

## ğŸ–¼ï¸ ExibiÃ§Ã£o 3D: `BP_ContextDisplay`

- Usa um `WidgetComponent` no mundo 3D para exibir imagens ou vÃ­deos
- Renderiza:
  - `WBP_DisplayPanel` para UI multimÃ­dia
  - VÃ­deo com `MediaPlayer` e `MediaTexture`
  - Modelos 3D com `StaticMeshComponent` animado com `Timeline`

---

## âš™ï¸ LÃ³gica Visual

- DetecÃ§Ã£o de keywords via `Contains (String)` com normalizaÃ§Ã£o (sem acentos)
- ExibiÃ§Ã£o animada com `Timeline` para crescimento do modelo 3D
- Evita delay visual com inicializaÃ§Ã£o forÃ§ada de visibilidade/escala

---

## ğŸ”„ Fluxo de ExecuÃ§Ã£o

1. O bot fala (evento via Convai)
2. O texto Ã© enviado Ã  API Hugging Face com os `candidate_labels` derivados da `DT_ContextAssets`
3. Se uma **keyword** da `DT_KeywordAssets` for detectada:
   - O asset correspondente Ã© exibido
4. SenÃ£o, o contexto retornado pela API Ã© utilizado para exibir o asset via `DT_ContextAssets`

---

## ğŸ“¦ Como Expandir

- Adicionar suporte a mÃºltiplas keywords por entrada
- Usar IA para gerar assets em tempo real (ex: via imagem/vÃ­deo de LLM)
- Integrar sistema de busca ou histÃ³rico do que foi mostrado

---

## ğŸ§ª Requisitos

- Unreal Engine 5.3
- Plugins:
  - Convai (ativado no projeto)
  - HttpBlueprint (para requisiÃ§Ãµes HTTP)

---

## ğŸ“‚ OrganizaÃ§Ã£o de Pastas (Recomendada)

/Blueprints/               â†’ LÃ³gica principal em Blueprints
/Characters/               â†’ Personagens e suas Blueprint Classes
/ContextObjects/           â†’ Ator e lÃ³gica de exibiÃ§Ã£o baseada em contexto e palavras-chave
/Assets/                   â†’ Texturas, malhas e vÃ­deos utilizados
/Developers/               â†’ Dados temporÃ¡rios ou pessoais de devs
/FirstPerson/, /FPWeapon/  â†’ ConteÃºdo do template First Person
/LevelPrototyping/         â†’ NÃ­veis de teste ou layout
/MetaHumans/               â†’ Personagens MetaHuman

## ğŸ“§ Contato

Linkedin: https://www.linkedin.com/in/jesus-abrah%C3%A3o-adad-filho-b68b20141/
